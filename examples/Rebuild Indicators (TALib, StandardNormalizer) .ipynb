{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "from talib.abstract import Function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gym import Space\n",
    "from copy import copy\n",
    "from abc import abstractmethod\n",
    "from typing import Union, List, Callable, Dict\n",
    "\n",
    "from tensortrade.features import FeatureTransformer\n",
    "from loguru import logger\n",
    "\n",
    "class TAlibIndicator(FeatureTransformer):\n",
    "    \"\"\"Adds one or more TAlib indicators to a data frame, based on existing open, high, low, and close column values.\"\"\"\n",
    "\n",
    "    def __init__(self, indicators: List[str], lows: Union[List[float], List[int]] = None, highs: Union[List[float], List[int]] = None, **kwargs):\n",
    "        indicators = self._error_check(indicators)\n",
    "        self._indicator_names = [indicator.upper() for indicator in indicators]\n",
    "        self._indicators = [getattr(talib, name.split('-')[0]) for name in self._indicator_names]\n",
    "        # Here we get the stats for each indicator for TA-Lib\n",
    "        self._stats = {indicator:self._get_info(indicator) for indicator in self._indicator_names}\n",
    "        \n",
    "    def _error_check(self, a:List[str])->List[str]:\n",
    "        \"\"\" Check for errors common errors\"\"\"\n",
    "        err_indexes = []\n",
    "        for n, i in enumerate(a):\n",
    "            if i == \"BBAND\":\n",
    "                a[n] = \"BBANDS\"\n",
    "            elif i == \"BB\":\n",
    "                a[n] = \"BBANDS\"\n",
    "            elif i == \"RIS\":\n",
    "                a[n] = \"RSI\"\n",
    "            elif i == \"\":\n",
    "                err_indexes.append(n)\n",
    "            elif i == None:\n",
    "                err_indexes.append(n)\n",
    "        for n in sorted(err_indexes, reverse=True):\n",
    "            del a[n]\n",
    "        return a\n",
    "    \n",
    "\n",
    "    def _get_info(self, indicator_name:str) -> Dict:\n",
    "        \"\"\" Get the relavent indicator parameters and inputs \"\"\"\n",
    "        if indicator_name is None:\n",
    "            print(\"Usage: help_indicator(symbol), symbol is indicator name\")\n",
    "            return {\n",
    "                \"parameters\": {},\n",
    "                \"inputs\": []\n",
    "            }\n",
    "        else:\n",
    "            upper_code = indicator_name.upper()\n",
    "            if upper_code not in talib.get_functions():\n",
    "                print(f\"ERROR: indicator {upper_code} not in list\")\n",
    "                return {\n",
    "                    \"parameters\": {},\n",
    "                    \"inputs\": []\n",
    "                }\n",
    "            else:\n",
    "                func = Function(upper_code)\n",
    "                parameters = dict(func.parameters)\n",
    "                inputs = list(func.input_names.values())\n",
    "                return {\n",
    "                    \"parameters\": parameters,\n",
    "                    \"inputs\": inputs\n",
    "                }\n",
    "\n",
    "    def _match_inputs(self, x_column:list, inputs:list):\n",
    "        \"\"\" Search through inputs to match outputs. It only goes through common inputs \"\"\"\n",
    "        real_inputs = []\n",
    "        for inp in inputs:\n",
    "            if inp == \"close\":\n",
    "                if inp in x_column:\n",
    "                    real_inputs.append(inp)\n",
    "                if \"Close\" in x_column:\n",
    "                    real_inputs.append(\"Close\")\n",
    "            elif inp == \"open\":\n",
    "                if inp in x_column:\n",
    "                    real_inputs.append(inp)\n",
    "                elif \"Open\" in x_column:\n",
    "                    real_inputs.append(\"Open\")\n",
    "            elif inp == \"high\":\n",
    "                if inp in x_column:\n",
    "                    real_inputs.append(inp)\n",
    "                elif \"High\" in x_column:\n",
    "                    real_inputs.append(\"High\")\n",
    "            elif inp == \"low\":\n",
    "                if inp in x_column:\n",
    "                    real_inputs.append(inp)\n",
    "                elif \"Low\" in x_column:\n",
    "                    real_inputs.append(\"Low\")\n",
    "            elif inp == \"volume\":\n",
    "                if inp in x_column:\n",
    "                    real_inputs.append(inp)\n",
    "                elif \"VolumeTo\" in x_column:\n",
    "                    real_inputs.append(\"VolumeTo\")\n",
    "        return real_inputs\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        for idx, indicator in enumerate(self._indicators):\n",
    "            \n",
    "            indicator_name = self._indicator_names[idx]\n",
    "            logger.debug(indicator_name)\n",
    "            indicator_params = self._stats[indicator_name]['parameters']\n",
    "            indicator_inputs = self._stats[indicator_name][\"inputs\"]\n",
    "            # Convert inputs into something that we'd commonly run to\n",
    "            matched_inputs = self._match_inputs(list(X.columns), indicator_inputs)\n",
    "            indicator_args = [X[arg].values for arg in matched_inputs]\n",
    "            if indicator_name == 'BBANDS':\n",
    "                upper, middle, lower = indicator(*indicator_args,**indicator_params)\n",
    "\n",
    "                X[\"bb_upper\"] = upper\n",
    "                X[\"bb_middle\"] = middle\n",
    "                X[\"bb_lower\"] = lower\n",
    "            else:\n",
    "                try:\n",
    "                    value = indicator(*indicator_args,**indicator_params)\n",
    "\n",
    "                    if type(value) == tuple:\n",
    "                        X[indicator_name] = value[0][0]\n",
    "                    else:\n",
    "                        X[indicator_name] = value\n",
    "\n",
    "                except:\n",
    "                    X[indicator_name] = indicator(*indicator_args,**indicator_params)[0]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tensortrade.features.scalers import MinMaxNormalizer, ComparisonNormalizer, PercentChangeNormalizer\n",
    "from tensortrade.features.stationarity import FractionalDifference\n",
    "\n",
    "ohlcv_data = pd.read_csv('./data/Coinbase_BTCUSD_1h.csv', skiprows=1)\n",
    "ohlcv_data = ohlcv_data[['open','high','low','close','volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taindicator = TAlibIndicator(indicators=[\"BBAND\", \"RSI\", \"EMA\", \"SMA\", \"\", None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../tests/data/input/coinbase-1h-btc-usd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 22:30:43.110 | DEBUG    | __main__:transform:103 - BBANDS\n",
      "2019-12-13 22:30:43.114 | DEBUG    | __main__:transform:103 - RSI\n",
      "2019-12-13 22:30:43.116 | DEBUG    | __main__:transform:103 - EMA\n",
      "2019-12-13 22:30:43.118 | DEBUG    | __main__:transform:103 - SMA\n"
     ]
    }
   ],
   "source": [
    "transformed = taindicator.transform(df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.to_csv('../tests/data/outputs/ta_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gym import Space\n",
    "from copy import copy\n",
    "from typing import Union, List, Tuple\n",
    "from loguru import logger\n",
    "from tensortrade.features.feature_transformer import FeatureTransformer\n",
    "\n",
    "\n",
    "class StandardNormalizer(FeatureTransformer):\n",
    "    \"\"\"A transformer for normalizing values within a feature pipeline by removing the mean and scaling to unit variance.\"\"\"\n",
    "\n",
    "    def __init__(self, columns: Union[List[str], str, None] = None, feature_min=0, feature_max=1, inplace=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            columns (optional): A list of column names to normalize.\n",
    "            feature_min (optional): The minimum value in the range to scale to.\n",
    "            feature_max (optional): The maximum value in the range to scale to.\n",
    "            inplace (optional): If `False`, a new column will be added to the output for each input column.\n",
    "        \"\"\"\n",
    "        super().__init__(columns=columns, inplace=inplace)\n",
    "\n",
    "        self._feature_min = feature_min\n",
    "        self._feature_max = feature_max\n",
    "\n",
    "        if feature_min >= feature_max:\n",
    "            raise ValueError(\"feature_min must be less than feature_max\")\n",
    "\n",
    "        self._history = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self._history = {}\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.columns is None:\n",
    "            self.columns = list(X.select_dtypes('number').columns)\n",
    "        \n",
    "        for column in self.columns:\n",
    "            if self._inplace == True:\n",
    "                X[column] = (X[column] - X[column].mean())/X[column].std()\n",
    "            else:\n",
    "                X[f\"{column}_scaled\"] = (X[column] - X[column].mean())/X[column].std()\n",
    "            \n",
    "        return X.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardNormalizer()\n",
    "transformed = standard.transform(ohlcv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.to_csv('../tests/data/outputs/standard_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_transformed = min_max.transform(ohlcv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_transformed.to_csv('../tests/data/outputs/min_max_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_normalizer = ComparisonNormalizer()\n",
    "\n",
    "com_normalizer.transform(ohlcv_data).to_csv('../tests/data/outputs/com_norm_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_normalizer = PercentChangeNormalizer()\n",
    "pct_normalizer.transform(ohlcv_data).to_csv('../tests/data/outputs/pct_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.features import FeaturePipeline\n",
    "from tensortrade.features.scalers import MinMaxNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = FeaturePipeline(\n",
    "    steps=[\n",
    "        TAlibIndicator(indicators=[\"BBAND\", \"RSI\", \"EMA\", \"SMA\", \"\", None]),\n",
    "        MinMaxNormalizer(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 22:57:48.573 | DEBUG    | __main__:transform:103 - BBANDS\n",
      "2019-12-13 22:57:48.577 | DEBUG    | __main__:transform:103 - RSI\n",
      "2019-12-13 22:57:48.579 | DEBUG    | __main__:transform:103 - EMA\n",
      "2019-12-13 22:57:48.581 | DEBUG    | __main__:transform:103 - SMA\n"
     ]
    }
   ],
   "source": [
    "feature_pipeline.transform(ohlcv_data).dropna().to_csv('../tests/data/outputs/feature_pipeline_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
